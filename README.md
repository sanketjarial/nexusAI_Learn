
# NexusAI Learn â€” Student Learning Portal (Phase 1: Normal Chat)

> A full-stack AI-assisted learning platform built using **Angular**, **NestJS**, **PostgreSQL**, and **Ollama**.  
> This phase focuses on the **Normal Chat Flow**, laying the groundwork for RAG, MCP, and Agentic AI in later stages.

---

## ğŸš€ Overview

NexusAI Learn is a student-oriented learning portal designed to showcase practical AI capabilities â€” including local LLM chat, retrieval-augmented learning, intelligent planning, and note-based reasoning.

**Tech Stack:**
- **Frontend:** Angular  
- **Backend:** NestJS  
- **Database:** PostgreSQL (with pgvector planned for RAG)  
- **LLM Engine:** Ollama (local inference)  

---

## ğŸ§© Phase 1: Normal Chat Flow

The first milestone of NexusAI Learn focuses on a **simple chat system** that connects Angular â†’ NestJS â†’ Ollama.

This forms the base for integrating Retrieval-Augmented Generation (RAG), Model Context Protocol (MCP), and Agentic AI workflows in the next phases.

---

## ğŸ§± Core Database Schema

```sql
-- Users
CREATE TABLE users (
  id uuid primary key default gen_random_uuid(),
  name text,
  email text unique,
  password_hash text,
  created_at timestamptz default now()
);

-- Conversations (each represents a single chat session)
CREATE TABLE conversations (
  id uuid primary key default gen_random_uuid(),
  user_id uuid references users(id),
  title text,
  mode text default 'chat',
  summary text,
  created_at timestamptz default now(),
  last_message_at timestamptz default now()
);

-- Messages (individual messages inside each conversation)
CREATE TABLE messages (
  id uuid primary key default gen_random_uuid(),
  conversation_id uuid references conversations(id),
  sender text, -- 'user' | 'assistant' | 'system'
  content text,
  meta jsonb,
  created_at timestamptz default now()
);
```

---

## âš™ï¸ Chat Flow Architecture

1. **Frontend (Angular)** â€” Provides a chat UI where users can send messages and view AI responses.
2. **Backend (NestJS)** â€” Handles requests, stores messages, and proxies user prompts to **Ollama**.
3. **Ollama** â€” Runs locally to generate chat completions.

### Flow

```
User â†’ Angular â†’ NestJS (/chat/message)
      â†“
   Ollama (via HTTP)
      â†“
NestJS saves (user + AI messages)
      â†“
Angular displays conversation
```

---

## ğŸ§  Example Endpoints

### `POST /chat/message`
Send a message and get an AI reply.

**Request:**
```json
{
  "conversationId": "uuid",
  "prompt": "Explain binary search",
  "systemPrompt": "You are a helpful tutor."
}
```

**Response:**
```json
{
  "assistantMessage": "Binary search works by dividing the array...",
  "conversationId": "uuid"
}
```

### `GET /chat/conversations`
List all user conversations.

### `GET /chat/conversations/:id/messages`
Fetch all messages for a specific chat session.

---

## ğŸ§° Folder Structure

```
/client              # Angular frontend
/server              # NestJS backend
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ auth/
  â”‚   â”œâ”€â”€ users/
  â”‚   â”œâ”€â”€ chat/
  â”‚   â”œâ”€â”€ notes/           # Placeholder for future RAG
  â”‚   â””â”€â”€ plan/            # Placeholder for future agent planner
  â”œ
  â”œâ”€â”€ main.ts
  â””â”€â”€ app.module.ts
/database
  â””â”€â”€ migrations.sql
```

---

## âš¡ Environment Variables

```env
PORT=3000
DATABASE_URL=postgres://postgres:postgres@localhost:5432/nexusai
JWT_SECRET=supersecret
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3
```

---

## ğŸ§  Future Phases

| Phase | Focus | Description |
|--------|--------|-------------|
| âœ… Phase 1 | **Normal Chat** | Angular â†’ NestJS â†’ Ollama chat completion |
| ğŸ”„ Phase 2 | **RAG** | Add embeddings + pgvector for note-based retrieval |
| ğŸ”„ Phase 3 | **MCP** | Implement tool-based reasoning protocol |
| ğŸ”„ Phase 4 | **Agentic AI** | Introduce planning + autonomous reasoning for study plans |

---

## ğŸ’¬ Developer Notes

- The chat schema (`conversations`, `messages`) provides clean separation for chat sessions and message logs.
- The backend can easily extend to RAG by embedding notes and linking retrieval context per conversation.
- The Ollama integration keeps everything **local-first** and **private**.
- Angular frontend can reuse the same API for later RAG/Agent modes.

---

## ğŸªª License

MIT License Â© 2025 Sanket  
Built to learn, teach, and show what local AI can do.

---

**Next Steps:**  
Once you confirm this setup, we can scaffold:
- NestJS Chat Module (Controller + Service)
- Angular Chat UI
- Optional Docker Compose for Postgres + Ollama
